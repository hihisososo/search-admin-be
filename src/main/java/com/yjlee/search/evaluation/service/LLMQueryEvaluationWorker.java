package com.yjlee.search.evaluation.service;

import static com.yjlee.search.evaluation.constants.EvaluationConstants.EVALUATION_SOURCE_LLM;

import co.elastic.clients.elasticsearch.ElasticsearchClient;
import co.elastic.clients.elasticsearch.core.GetRequest;
import co.elastic.clients.elasticsearch.core.GetResponse;
import co.elastic.clients.elasticsearch.core.MgetRequest;
import co.elastic.clients.elasticsearch.core.MgetResponse;
import co.elastic.clients.elasticsearch.core.mget.MultiGetResponseItem;
import com.fasterxml.jackson.databind.JsonNode;
import com.fasterxml.jackson.databind.ObjectMapper;
import com.yjlee.search.common.constants.ESFields;
import com.yjlee.search.common.util.PromptTemplateLoader;
import com.yjlee.search.evaluation.model.EvaluationQuery;
import com.yjlee.search.evaluation.model.QueryProductMapping;
import com.yjlee.search.evaluation.model.RelevanceStatus;
import com.yjlee.search.evaluation.repository.EvaluationQueryRepository;
import com.yjlee.search.evaluation.repository.QueryProductMappingRepository;
import com.yjlee.search.index.dto.ProductDocument;
import java.util.ArrayList;
import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.Optional;
import java.util.concurrent.CompletableFuture;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.scheduling.annotation.Async;
import org.springframework.stereotype.Service;

/** LLM í‰ê°€ë¥¼ ìœ„í•œ ë³„ë„ Worker ì„œë¹„ìŠ¤ Spring AOP ë¬¸ì œ í•´ê²°ì„ ìœ„í•´ ë¶„ë¦¬ëœ ì„œë¹„ìŠ¤ (ìˆœí™˜ ì˜ì¡´ì„± ë°©ì§€) */
@Slf4j
@Service
@RequiredArgsConstructor
public class LLMQueryEvaluationWorker {

  private final LLMService llmService;
  private final ElasticsearchClient elasticsearchClient;
  private final EvaluationQueryRepository evaluationQueryRepository;
  private final QueryProductMappingRepository queryProductMappingRepository;
  private final ObjectMapper objectMapper;
  private final PromptTemplateLoader promptTemplateLoader;

  @Value("${evaluation.llm.batch-size:20}")
  private int defaultBatchSize;

  /** ê°œë³„ ì¿¼ë¦¬ë¥¼ ë¹„ë™ê¸°ë¡œ í‰ê°€ (ì‹¤ì œ ë©€í‹° ì“°ë ˆë”©) */
  @Async("llmTaskExecutor")
  public CompletableFuture<Void> evaluateQueryAsync(String query) {
    try {
      log.info("ğŸ§µ ì¿¼ë¦¬ '{}' í‰ê°€ ì‹œì‘ - ìŠ¤ë ˆë“œ: {}", query, Thread.currentThread().getName());

      // ì‹¤ì œ í‰ê°€ ë¡œì§ (ë™ì¼í•œ ë¡œì§ì´ì§€ë§Œ Workerì—ì„œ ì‹¤í–‰)
      evaluateQueryCandidates(query);

      log.info("âœ… ì¿¼ë¦¬ '{}' í‰ê°€ ì™„ë£Œ - ìŠ¤ë ˆë“œ: {}", query, Thread.currentThread().getName());
      return CompletableFuture.completedFuture(null);
    } catch (Exception e) {
      log.error("âš ï¸ ì¿¼ë¦¬ '{}'ì˜ í›„ë³´êµ° í‰ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ - ìŠ¤ë ˆë“œ: {}", query, Thread.currentThread().getName(), e);
      CompletableFuture<Void> failed = new CompletableFuture<>();
      failed.completeExceptionally(e);
      return failed;
    }
  }

  /** ë‹¨ì¼ ì¿¼ë¦¬ì˜ í›„ë³´êµ° í‰ê°€ (ì‹¤ì œ LLM í˜¸ì¶œ) */
  private void evaluateQueryCandidates(String query) {
    log.info("ì¿¼ë¦¬ '{}'ì˜ í›„ë³´êµ° ë²Œí¬ í‰ê°€ ì‹œì‘", query);

    Optional<EvaluationQuery> evaluationQueryOpt = evaluationQueryRepository.findByQuery(query);
    if (evaluationQueryOpt.isEmpty()) {
      log.warn("âš ï¸ í‰ê°€ ì¿¼ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {}", query);
      return;
    }

    EvaluationQuery evaluationQuery = evaluationQueryOpt.get();
    List<QueryProductMapping> mappings =
        queryProductMappingRepository.findByEvaluationQuery(evaluationQuery);
    if (mappings.isEmpty()) {
      log.warn("âš ï¸ ì¿¼ë¦¬ '{}'ì— ëŒ€í•œ í›„ë³´êµ°ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € í›„ë³´êµ°ì„ ìƒì„±í•´ì£¼ì„¸ìš”.", query);
      return;
    }

    log.info("ì¿¼ë¦¬ '{}': {}ê°œ í›„ë³´êµ° í‰ê°€ ì‹œì‘", query, mappings.size());

    // ì‹¤ì œ LLM í‰ê°€ ì‹¤í–‰ (LLMCandidateEvaluationService ë¡œì§ì„ ì§ì ‘ êµ¬í˜„)
    evaluateWithLLM(query, evaluationQuery, mappings);
  }

  /** LLMì„ ì‚¬ìš©í•œ ì‹¤ì œ í‰ê°€ ë¡œì§ */
  private void evaluateWithLLM(
      String query, EvaluationQuery evaluationQuery, List<QueryProductMapping> mappings) {
    // 1. ëª¨ë“  ìƒí’ˆ ì •ë³´ë¥¼ ESì—ì„œ ë²Œí¬ ì¡°íšŒ
    List<String> productIds = mappings.stream().map(QueryProductMapping::getProductId).toList();
    Map<String, ProductDocument> productMap = getProductsBulk(productIds);
    log.info("ğŸ” ES ë²Œí¬ ì¡°íšŒ ì™„ë£Œ: {}/{}ê°œ ìƒí’ˆ", productMap.size(), productIds.size());

    // 2. ìœ íš¨í•œ ë§¤í•‘ë§Œ í•„í„°ë§
    List<ProductDocument> products = new ArrayList<>();
    List<QueryProductMapping> validMappings = new ArrayList<>();

    for (QueryProductMapping mapping : mappings) {
      ProductDocument product = productMap.get(mapping.getProductId());
      if (product != null) {
        products.add(product);
        validMappings.add(mapping);
      } else {
        log.warn("âš ï¸ ìƒí’ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {}", mapping.getProductId());
      }
    }

    if (products.isEmpty()) {
      log.warn("âš ï¸ ì¿¼ë¦¬ '{}'ì— ëŒ€í•œ ìœ íš¨í•œ ìƒí’ˆì´ ì—†ìŠµë‹ˆë‹¤", query);
      return;
    }

    // 3. ìƒí’ˆì„ ì„¤ì •ëœ ë°°ì¹˜ í¬ê¸°ë¡œ ë‚˜ëˆ„ì–´ ì²˜ë¦¬
    int batchSize = defaultBatchSize;
    List<QueryProductMapping> updatedMappings = new ArrayList<>();

    for (int i = 0; i < products.size(); i += batchSize) {
      int endIndex = Math.min(i + batchSize, products.size());
      List<ProductDocument> batchProducts = products.subList(i, endIndex);
      List<QueryProductMapping> batchMappings = validMappings.subList(i, endIndex);

      try {
        log.info("ğŸ”„ ë°°ì¹˜ ì²˜ë¦¬ ì‹œì‘: {}-{}/{}", i + 1, endIndex, products.size());

        // ë°°ì¹˜ë³„ í”„ë¡¬í”„íŠ¸ ìƒì„±
        String batchPrompt = buildBulkEvaluationPrompt(query, batchProducts);

        // ë°°ì¹˜ë³„ LLM í˜¸ì¶œ
        log.info("ğŸ¤– LLM API í˜¸ì¶œ ì‹œì‘ (ë°°ì¹˜ í¬ê¸°: {})", batchProducts.size());
        String batchResponse = llmService.callLLMAPI(batchPrompt);

        if (batchResponse == null || batchResponse.trim().isEmpty()) {
          log.warn("âš ï¸ LLM API ì‘ë‹µì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤");
          throw new RuntimeException("LLM API ì‘ë‹µì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤");
        }

        log.info("âœ… LLM API ì‘ë‹µ ìˆ˜ì‹  (ê¸¸ì´: {}ì)", batchResponse.length());
        log.debug("LLM ì‘ë‹µ ë‚´ìš©: {}", batchResponse);

        // ë°°ì¹˜ë³„ ì‘ë‹µ íŒŒì‹±
        List<QueryProductMapping> batchResults =
            parseBulkEvaluationResponse(query, batchMappings, batchResponse);
        updatedMappings.addAll(batchResults);

        log.info(
            "âœ… ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ: {}-{}/{} (ì„±ê³µ: {}ê°œ)",
            i + 1,
            endIndex,
            products.size(),
            batchResults.size());

      } catch (Exception e) {
        log.warn("âš ï¸ ë°°ì¹˜ {}-{} ì²˜ë¦¬ ì‹¤íŒ¨", i + 1, endIndex, e);
        // ì‹¤íŒ¨í•œ ë°°ì¹˜ëŠ” ì‹¤íŒ¨ ë§¤í•‘ìœ¼ë¡œ ì²˜ë¦¬
        List<QueryProductMapping> failedBatch =
            createFailedMappings(query, batchMappings, "ë°°ì¹˜ ì²˜ë¦¬ ì‹¤íŒ¨: " + e.getMessage());
        updatedMappings.addAll(failedBatch);
      }
    }

    // 4. ì¼ê´„ ì €ì¥
    if (!updatedMappings.isEmpty()) {
      queryProductMappingRepository.saveAll(updatedMappings);
      log.info("âœ… ì¿¼ë¦¬ '{}'ì˜ í›„ë³´êµ° ë²Œí¬ í‰ê°€ ì™„ë£Œ: {}ê°œ ìƒí’ˆ", query, updatedMappings.size());
    }
  }

  /** ESì—ì„œ ì—¬ëŸ¬ ìƒí’ˆì„ í•œ ë²ˆì— ì¡°íšŒ (ë²Œí¬ ì¡°íšŒ) */
  private Map<String, ProductDocument> getProductsBulk(List<String> productIds) {
    if (productIds.isEmpty()) {
      return new HashMap<>();
    }

    try {
      log.debug("ğŸ” ES ë²Œí¬ ì¡°íšŒ ì‹œì‘: {}ê°œ ìƒí’ˆ", productIds.size());

      // MultiGet ìš”ì²­ ìƒì„±
      MgetRequest.Builder requestBuilder =
          new MgetRequest.Builder().index(ESFields.PRODUCTS_SEARCH_ALIAS);

      // ê° ìƒí’ˆ IDë¥¼ ìš”ì²­ì— ì¶”ê°€
      for (String productId : productIds) {
        requestBuilder.ids(productId);
      }

      MgetRequest request = requestBuilder.build();
      MgetResponse<ProductDocument> response =
          elasticsearchClient.mget(request, ProductDocument.class);

      // ì‘ë‹µì„ Mapìœ¼ë¡œ ë³€í™˜
      Map<String, ProductDocument> productMap = new HashMap<>();
      for (MultiGetResponseItem<ProductDocument> item : response.docs()) {
        if (item.result() != null && item.result().found()) {
          String productId = item.result().id();
          ProductDocument product = item.result().source();
          if (product != null) {
            productMap.put(productId, product);
          }
        }
      }

      log.debug("ğŸ” ES ë²Œí¬ ì¡°íšŒ ì™„ë£Œ: {}/{}ê°œ ìƒí’ˆ ì¡°íšŒ ì„±ê³µ", productMap.size(), productIds.size());
      return productMap;

    } catch (Exception e) {
      log.error("âš ï¸ ES ë²Œí¬ ì¡°íšŒ ì‹¤íŒ¨", e);
      // ë²Œí¬ ì¡°íšŒ ì‹¤íŒ¨ ì‹œ ê°œë³„ ì¡°íšŒë¡œ í´ë°±
      log.warn("ë²Œí¬ ì¡°íšŒ ì‹¤íŒ¨, ê°œë³„ ì¡°íšŒë¡œ í´ë°± ì‹¤í–‰");
      return getProductsIndividually(productIds);
    }
  }

  /** ë²Œí¬ ì¡°íšŒ ì‹¤íŒ¨ ì‹œ ê°œë³„ ì¡°íšŒë¡œ í´ë°± */
  private Map<String, ProductDocument> getProductsIndividually(List<String> productIds) {
    Map<String, ProductDocument> productMap = new HashMap<>();

    for (String productId : productIds) {
      ProductDocument product = getProductFromES(productId);
      if (product != null) {
        productMap.put(productId, product);
      }
    }

    return productMap;
  }

  private ProductDocument getProductFromES(String productId) {
    try {
      GetRequest request =
          GetRequest.of(g -> g.index(ESFields.PRODUCTS_SEARCH_ALIAS).id(productId));

      GetResponse<ProductDocument> response =
          elasticsearchClient.get(request, ProductDocument.class);
      return response.found() ? response.source() : null;
    } catch (Exception e) {
      log.warn("âš ï¸ ESì—ì„œ ìƒí’ˆ {} ì¡°íšŒ ì‹¤íŒ¨", productId, e);
      return null;
    }
  }

  private String buildBulkEvaluationPrompt(String query, List<ProductDocument> products) {
    // ìƒí’ˆ ë¦¬ìŠ¤íŠ¸ ë¬¸ìì—´ ìƒì„±
    StringBuilder productListBuilder = new StringBuilder();
    for (int i = 0; i < products.size(); i++) {
      ProductDocument product = products.get(i);
      productListBuilder.append("ìƒí’ˆ ").append(i + 1).append(":\n");
      productListBuilder.append("- ID: ").append(product.getId()).append("\n");
      productListBuilder
          .append("- ìƒí’ˆëª…: ")
          .append(product.getNameRaw() != null ? product.getNameRaw() : "N/A")
          .append("\n");
      productListBuilder
          .append("- ìŠ¤í™: ")
          .append(product.getSpecsRaw() != null ? product.getSpecsRaw() : "N/A")
          .append("\n\n");
    }

    // í…œí”Œë¦¿ ë³€ìˆ˜ ì„¤ì •
    Map<String, String> variables = new HashMap<>();
    variables.put("QUERY", query);
    variables.put("PRODUCT_COUNT", String.valueOf(products.size()));
    variables.put("PRODUCT_LIST", productListBuilder.toString());

    return promptTemplateLoader.loadTemplate("bulk-product-relevance-evaluation.txt", variables);
  }

  private List<QueryProductMapping> parseBulkEvaluationResponse(
      String query, List<QueryProductMapping> mappings, String response) {
    List<QueryProductMapping> updatedMappings = new ArrayList<>();

    try {
      String cleanedResponse = cleanJsonResponse(response);
      JsonNode jsonArray = objectMapper.readTree(cleanedResponse);

      if (!jsonArray.isArray()) {
        log.warn("âš ï¸ LLM ì‘ë‹µì´ ë°°ì—´ í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤: {}", response);
        return createFailedMappings(query, mappings, "ì‘ë‹µ í˜•ì‹ ì˜¤ë¥˜");
      }

      // ì‘ë‹µê³¼ ë§¤í•‘ì„ ìˆœì„œëŒ€ë¡œ ì²˜ë¦¬
      for (int i = 0; i < mappings.size(); i++) {
        QueryProductMapping mapping = mappings.get(i);

        try {
          if (i < jsonArray.size()) {
            JsonNode evaluation = jsonArray.get(i);

            boolean isRelevant = evaluation.path("isRelevant").asBoolean(false);
            String reason = evaluation.path("reason").asText("");
            double confidence = evaluation.path("confidence").asDouble(0.0);

            String evaluationReason = String.format("%s (ì‹ ë¢°ë„: %.2f)", reason, confidence);

            QueryProductMapping updatedMapping =
                QueryProductMapping.builder()
                    .id(mapping.getId())
                    .evaluationQuery(mapping.getEvaluationQuery())
                    .productId(mapping.getProductId())
                    .productName(mapping.getProductName())
                    .productSpecs(mapping.getProductSpecs())
                    .relevanceStatus(RelevanceStatus.fromBoolean(isRelevant))
                    .evaluationReason(evaluationReason)
                    .evaluationSource(EVALUATION_SOURCE_LLM)
                    .build();

            updatedMappings.add(updatedMapping);

          } else {
            // ì‘ë‹µì— í•´ë‹¹ ìƒí’ˆì´ ì—†ëŠ” ê²½ìš°
            QueryProductMapping failedMapping = createFailedMapping(mapping, "ì‘ë‹µ ëˆ„ë½");
            updatedMappings.add(failedMapping);
          }

        } catch (Exception e) {
          log.warn("âš ï¸ ìƒí’ˆ {} í‰ê°€ ê²°ê³¼ íŒŒì‹± ì‹¤íŒ¨", mapping.getProductId(), e);
          QueryProductMapping failedMapping =
              createFailedMapping(mapping, "íŒŒì‹± ì‹¤íŒ¨: " + e.getMessage());
          updatedMappings.add(failedMapping);
        }
      }

    } catch (Exception e) {
      log.warn("âš ï¸ ë²Œí¬ í‰ê°€ ì‘ë‹µ ì „ì²´ íŒŒì‹± ì‹¤íŒ¨: {}", response, e);
      return createFailedMappings(query, mappings, "ì „ì²´ íŒŒì‹± ì‹¤íŒ¨: " + e.getMessage());
    }

    return updatedMappings;
  }

  private List<QueryProductMapping> createFailedMappings(
      String query, List<QueryProductMapping> mappings, String errorMessage) {
    List<QueryProductMapping> failedMappings = new ArrayList<>();

    for (QueryProductMapping mapping : mappings) {
      QueryProductMapping failedMapping = createFailedMapping(mapping, errorMessage);
      failedMappings.add(failedMapping);
    }

    return failedMappings;
  }

  private QueryProductMapping createFailedMapping(
      QueryProductMapping mapping, String errorMessage) {
    return QueryProductMapping.builder()
        .id(mapping.getId())
        .evaluationQuery(mapping.getEvaluationQuery())
        .productId(mapping.getProductId())
        .productName(mapping.getProductName())
        .productSpecs(mapping.getProductSpecs())
        .relevanceStatus(RelevanceStatus.IRRELEVANT)
        .evaluationReason("í‰ê°€ ì‹¤íŒ¨: " + errorMessage + " (ì‹ ë¢°ë„: 0.00)")
        .evaluationSource(EVALUATION_SOURCE_LLM)
        .build();
  }

  private String cleanJsonResponse(String response) {
    if (response == null || response.trim().isEmpty()) {
      return "{}";
    }

    String cleaned = response.trim();

    // Markdown ì½”ë“œ ë¸”ë¡ ì œê±°
    if (cleaned.startsWith("```json")) {
      cleaned = cleaned.substring(7);
    } else if (cleaned.startsWith("```")) {
      cleaned = cleaned.substring(3);
    }

    if (cleaned.endsWith("```")) {
      cleaned = cleaned.substring(0, cleaned.length() - 3);
    }

    return cleaned.trim();
  }
}
