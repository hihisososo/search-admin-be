## 검색평가

#### 개요
- 검색 품질을 정량적으로 평가할 수 있는 기능입니다
- 검색어 -> 정답 문서셋 구축 후 Precision, Recall 평가하도록 구현하였고, Precision, Recall 로 평가하도록 한 이유는 아래와 같습니다
  - 유저 데이터가 없으므로, CTR 등 유저 데이터 기반 평가가 불가 
  - NDCG 처럼 검색된 문서에 연관도 점수를 차등 부여하는 방식은, 짧은 키워드 나열 위주인 상품명 데이터에서는 효과적인 연관도 차등 부여가 힘들다고 판단하였습니다
- 참고한 문서는 아래와 같습니다
  - https://www.elastic.co/search-labs/blog/evaluating-search-relevance-part-2 (LLM 을 통한 연관도 평가)

#### 기능
- 쿼리 생성
  - 색인된 ES 문서에서 랜덤하게 아래 프롬프트를 이용해, 쿼리를 추천합니다
- 

### 문서 링크
- 상세 API 명세는 `docs/search-evaluation-apis.md`를 참고하세요.

 
#### 라벨링 운영 개요(간단 요약)
- 목적: LLM의 1차 자동 판단으로 라벨링 피로를 낮추고, 사용자는 애매한 사례만 빠르게 검수합니다.
- 절차:
  - 후보 수집: 쿼리별 관련 상품 후보를 충분히 모읍니다.
  - 1차 자동 라벨링: LLM이 관련 여부, 짧은 이유, 확신도를 제시합니다.
  - 트리아지: 확신도 기준으로 자동 확정 / 검수 필요 / 보류로 구분합니다.
  - 2차 검수: ‘검수 필요’만 1-클릭으로 확정하고 이유를 간단히 보완합니다.
  - 샘플 점검: 자동 확정 일부를 랜덤 샘플로 재검수하여 신뢰도를 확인합니다.
- 지표: Precision, Recall, F1을 제공하며, 최신 리포트를 화면에서 바로 확인할 수 있습니다.
- 비고: 확신도 임계값(예: 0.8/0.5)은 운영 상황에 맞게 조정합니다.